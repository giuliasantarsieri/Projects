---
title: "Projet 4M015"
author: "ALAM SANTARSIERI"
date: "23/12/2019"
output: html_document

---

## Introduction 

### Description du jeu de données original

Nous analyserons au cours de ce projet un jeu de données conçernant le nombres de suicides dans le monde en 2014. Le jeu de données nous donne le nombre de suicides dans chaque pays et catégorise les observations selon différentes variables.
Il contient trois variables qualitatives: l'age, le sexe et la génération.
Il contient également des variables quantitatives: le nombre total de suicides dans le pays, la taille de la population, la proportion de suicides par rapport à la taille de la population, le PIB par an et per capita et l'HDI (indice de développement humain). 

Voilà à quoi ressemble notre jeu de données original:

```{r,echo=FALSE}
data <- read.csv(file='age_sex_modified.csv',header=TRUE)
head(data)
```

### Objectif du projet 

L'objectif de ce projet va être de détérminer l'existence ou non d'une relation entre le nombre de suicides et différentes variables qualitatives, comme le sexe ou l'age d'une personne, ou quantitatives, comme le nombre de suicides ou l'Indice du Développement Humain d'un pays.
Dans cette optique, nous allons faire une régression simple, une régression multiple et une ANOVA.

### Traitement des données

Un traitement du jeu de données est nécessaire avant de commencer notre analyse:

- On fait tout d'abord le choix du supprimer la variable _génération_ car on retrouve la même information dans la variable _age_.

- La variable _HDI_ donne l'Indice de Développement Humain du pays qui est sensé être compris entre 0 et 1. Or, dans notre jeu de données, l' _HDI_ de certains pays a été multiplié par 1000 pour obtenir un nombre entier. On ramène donc toutes les observations à un nombre compris entre 0 et 1 avec une simple boucle.

- 3 données sont manquantes pour la variable _HDI_. Comme le nombre de données manquantes est très petit et l'indice de développement est une donnée très simple à obtenir, nous avons manuellement rajouté les données manquantes.

- La variable _gdp_for_year_, donnant le PIB par an d'un pays, est du type 'factor' dans notre jeu de données.
Ceci le rend assez compliqué à manipuler et il a fallu le convertir en nombre.


## Régression linéaire simple
 
### Traitement des données

Pour pouvoir effectuer une régression linéaire efficace, on traite notre jeu de données de la manière suivante:
- on regroupe le nombre total de suicides par pays (qui avant étaient catégorisés pas tranches d'age et par sexe) dans une unique nouvelle variable _deaths_
- on regroupe de la même manière la taille de la population pour chaque pays dans la variable _pop_
- on crée la variable _prop_ donnant la proportion de suicides sur le total de la population

On obtient donc le jeu de données suivant:

```{r setup, include=FALSE}
suicides <- read.csv(file='new_data.csv',header=TRUE)
head(suicides)
```

Ce nouveau jeu de données contient que des variables quantitatives et peut donc être utilisé pour faire une régression linéaire.

### Objectif

Dans cette partie, notre but est d'effectuer une régression linéaire simple. On souhaite en fait modéliser une relation linéaire entre la variable _deaths_, donnant le nombre de suicides dans un pays, et une variable quantitative de notre jeu de données. Notre objectif est d'établir un lien explicatif et/ou prévisionnel entre ces deux variables.

### Modèle 

On a sélectionné une variable réponse $y$ et on sélectionnera une variable explicative $x$, liées par le modèle suivant:

$y=\beta_0 + \beta_1x + \epsilon$ , $\epsilon$ étant la variable du bruit. Nous supposons que $\epsilon$ est une variable aléatoire centrée de variance $\sigma^2$ suivant une loi normale $N(0,\sigma^2)$.
On estimera donc $\beta_0$ et $\beta_1$ à l'aide de notre jeu de données.

### Sélection de la variable explicative

A l'aide du diagramme suivant, on visualise les relations entre toutes les variables de notre jeu de données:

```{r,echo=FALSE}
pairs(suicides[3:9,3:9])
```

```{r,echo=FALSE}
cor(suicides[,3:9])
```


Le coefficient de corrélation entre _deaths_ et _pop_ est égale à 0.89, donc très proche de 1. De même, le coefficient de corrélation entre _deaths_ et _gdp_for_year_ est très proche de 1 (0.87).
Ceci indique qu'il pourrait exister une forte relation linéaire entre la variable _deaths_ et ces variables.
Comme une relation entre le nombre de suicides dans un Pays et la taille de sa population nous ne semble par très intéressante à étudier (le lien entre les deux étant assez évident), nous effectuons une régression simple en fonction de la variable explicative _gdp_for_year_.
On a également effectué des régressions simples en utilisant les autres variables de notre jeu de données (qu'on n'incluera pas dans notre rapport), et on en a conclu que le relation avec la variable _gdp_for_year_ était la relation qui pouvait être le mieux modélisée par un modèle linéaire simple.

### Représentation graphique

```{r,echo=FALSE}
reg.simple <- lm(deaths~gdp_for_year, data=suicides)
plot(suicides$gdp_for_year,suicides$deaths,xlab='GDP per year',ylab='Deaths',main='Données')
abline(reg.simple,col='red')
points(suicides$gdp_for_year,reg.simple$fitted.values,col='blue')
text(suicides$gdp_for_year,suicides$deaths,suicides$country,cex=0.,pos=2)
```

En ajustant l'axe des abscisses, nous obtenons:

```{r,echo=FALSE}
plot(suicides$gdp_for_year,suicides$deaths,xlab='GDP per year',ylab='Deaths',xlim=c(0,1.0e+12),main='Données')
abline(reg.simple,col='red')
points(suicides$gdp_for_year,reg.simple$fitted.values,col='blue')

```

On remarque que la relation entre la variable _deaths_ et la variable _gdp_per_year_ est assez bien modélisée par une relation linéaire. Tout de même, on s'attend à avoir des observations atypiques dans notre jeu de données.
Le nombre de suicides pour des Pays tels que la Russie ou le Japon ne semble en effetcpas bien modélisé par notre modèle (ces observations pourraient donc être des valeurs aberrantes) et le nombre de suicides aux États Unis pourrait être une observation isolée.


### Estimation des paramètres


```{r, echo=FALSE}
summary(reg.simple)
```

Les coefficients $\beta_0$ (constante) et $\beta_1$ (de _gdp_for_year_) sont estimés à 9.362e+02 et 2.676e-09 respectivement.
La _p-valeur_ étant très petite pour la constante (inférieure à _2e-16_) et pour la variable _gdp_for_year_ (inférieure à _2e-16_), on rejette l'hypothèse $\ H_0$ selon laquelle les deux variables ne seraient pas significatives aux niveaux 1%, 5% et 10%.
Il semble donc exister une relation linéaire entre le nombre de suicides dans un Pays et son PIB en 2014.

## Validation du modèle 

### Analyse des résidus

Une première étape dans la validation de notre modèle consiste à vérifier l'absence d'observations atypiques dans notre jeu de données.

#### Valeurs abérrantes

```{r,echo=FALSE}
res_stud <- rstudent(reg.simple)
n <- length(suicides$X)
plot(1:n,res_stud,xlab='Index',ylab='Résidus studentisés',main='Valeurs abérrantes')
abline(-2,0,col='green')
abline(2,0,col='green')
IDval.ab <- (1:n)[abs(res_stud)>2]
points(IDval.ab, res_stud[IDval.ab], col = 'red', pch = 16) 
text(IDval.ab, res_stud[IDval.ab], IDval.ab, pos = 4, col = 'red')

```


Si l'échantillon ne contient pas de valeurs aberrantes, 95% des résidus studentisées (dans notre cas 889 valeurs) se trouvent dans l'intervalle [-2,2], correspondant aux quantiles d'une loi de Student à $\ n-p-1$ degrés de liberté pour $\alpha=95 \%$.

```{r,echo=FALSE}
length(IDval.ab)
```

Dans notre graphique, il y a 48 valeurs (c'est à dire 5,12% de l'échantillon) qui dépassent l'intervalle. On peut donc supposer la présence de valeurs abérrantes et pousser un peu l'étude.


#### Points levier et Distance de Cook

On poursuit notre recherche des valeurs atypiques avec la recherche de points leviers et en calculant la distance de Cook.

```{r,echo=FALSE}
levier <- hatvalues(reg.simple)
plot(1:n, levier,xlab = 'Index',ylab = 'Points leviers',main='Points leviers')
p <- reg.simple$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
abline(seuil1,0,col='green')
abline(seuil2,0,col='blue')
IDlev <- (1:n)[levier>seuil2]
text(IDlev, levier[IDlev], IDlev, pos = 4, col = 'red')
legend(x=700,y=0.06, col = c("blue","green"), lty = 1, legend = c("2p/n","3p/n") )
```

```{r,echo=FALSE}
cook <- cooks.distance(reg.simple)
s1 <- qf(0.5,p,n-p)
plot(1:n,cook,xlab='Index', main='Distance de Cook')
abline(s1,0,col='red')
s2 <- qf(0.1,p,n-p)
abline(s2,0,col='red')
```

Le jeu de données contient 12 points leviers dépassant le seuil $\ 3p/n$ qui influencent donc fortement le résultat de la régression. On pourrait éventuellement les supprimer, mais ces points n'ayant pas une distance de Cook trop élevée, et ces données nous apportant des informations importantes, nous décidons de ne pas supprimer ces observations.
En conclusion, ce jeu de données pourrait très probablement contenir des observations aberrantes et des observations influentes, mais nous décidons de ne pas les supprimer.

```{r,echo=FALSE}
plot(suicides$gdp_for_year, suicides$deaths, xlab = 'GDP for year', ylab = 'Deaths',
     main = 'Donnees avec valeurs aberrantes et points leviers')
abline(coef(reg.simple), col = 'orange')
points(suicides$gdp_for_year[IDval.ab], suicides$deaths[IDval.ab], col = 'blue', pch = 16) 
points(suicides$gdp_for_year[IDlev], suicides$deaths[IDlev], col = 'red', pch = 16) 
legend(1.0e+13,9000, c('abérrante', 'levier'), col = c('blue','red'), pch = 16)

```


#### Structure des résidus


On souhaite vérifier plusieurs hypothèses conçernant le vecteur $\epsilon$, vecteur des résidus de notre régression simple:

1) Les $\epsilon_i$ sont i.i.d., centrées et de variance $\sigma^2$ homogène
2) Le bruit $\epsilon$ est un vecteur gaussien. On pourrait alors affirmer qu'on a construit un modèle linéaire gaussien.


```{r,echo=FALSE}
n <- length(suicides$deaths)
residuals <- residuals(reg.simple)
plot(1:n,residuals,main='Résidus',xlab='Index',ylab='Residus')
rect(-50,5500,1000,12000,col=rgb(0,0,1.0,alpha=0.5))
rect(-50,-2500,1000,4700,col=rgb(0,0,1.0,alpha=0.5))
```

```{r,echo=FALSE}
res_stud <- rstudent(reg.simple)
rstand <- rstandard(reg.simple)
plot(1:n,rstand,col='black',xlab='Index', main='Résidus standardisés et résidus studentisés')
points(1:n,res_stud,col='pink')
legend(600 , 5.2,c('standardisé','studentisé'),col=c('black','pink'),pch=c(1,1))
```

Les résidus  semblent avoir une structure "par bandes".
Cela pourrait être expliqué par le fait qu'il y a plusieurs sous-populations distinctes.

#### Normalité des résidus

```{r, echo=FALSE}
quantiles_stud <- qt((1:n)/n,n-p-1)
plot(quantiles_stud,sort(res_stud),col='orange',main='QQ-plot des résidus',xlab='Student T(n-p-1)',ylab='Quantiles empiriques des résidus')
abline(0,1)
```



Les résidus studéntisés ne s'alignent pas le long de la première bissectrice et ne semblent donc pas suivre une loi de Student à $\ n-p-1$ degrés de liberté, ce qui nous amènerait à rejeter l'hypothèse de normalité des résidus.

On vérifie notre hypothèse avec deux tests:

```{r,echo=FALSE}
shapiro.test(residuals)
ks.test(x=(residuals-mean(residuals))/sd(residuals),y='pnorm')
```


On obtient une p-valeur très petite pour les deux tests, ce qui nous amène à rejeter l'hypothèse $\ H_0$: *"les résidus suivent une loi normale"*.
Donc on confirme notre hypothèse selon laquelle les résidus ne suivent pas une loi normale.

### Conclusion : Régression simple

D'après nos analyses, on peut conclure qu'il existe une relation linéaire positive (assez surprenante) entre le nombre de suicides et le PIB annuel, et que cette variable est donc significative pour expliquer la proportion de suicides.

Cependant, une régression linéaire simple semble insuffisante pour expliquer cette variable.
D'ailleurs, on ne peut pas appliquer un modèle linéaire gaussien à ces données car l'hypothèse de normalité n'est pas réspectée. On suppose également la présence de plusieurs sous-populations dans notre jeu de données, mais on n'ira pas plus loin dans notre analyse à ce niveau là.


## Régression linéaire multiple

### Modèle

On va chercher à modéliser par une régression linéaire multiple la  relation entre la variable _deaths_, donnant le nombre de suicides dans un pays et $\ n$ variables explicatives, que l'on va sélectionner.
Les hypothèses du modèle conçernant le bruit restent les mêmes que dans la régression simple.

### Séléction de variables

```{r,echo=FALSE}
reg.mult <- lm(deaths~.-country,data=suicides)
summary(reg.mult)
```

Parmi les variables à notre disposition, les variables _pop_, _prop_ et _gdp_for_year_ ont une p-valeur très petite et sont donc significatives aux niveaux 1%,5% et 10%. Ces variables sont à inclure dans notre modèle. La constante et la variable _gdp_per_pers_ sont signficatives au niveau 5% et pourraient être incluses dans notre modèle.

A l'aide de la fonction _regsubsets_, on poursuit dans le choix des variables explicatives.

En utilisant une méthode exhaustive, nous avons l'affichage suivant:

```{r,echo=FALSE}
library(leaps)
require(MASS)
summary(regsubsets(deaths~.-country,data=suicides),method='backward')
```

Les variables _hdi_, _pop_, _prop_ , _gdp_for_year_ et gdp_per_pers_ semblent être les meilleures variables explicatives pour notre modèle.

```{r,echo=FALSE}
library(leaps)
plot(regsubsets(deaths~.-country,data=suicides),scale='bic')
```


Ici, on cherche à minimiser le critère BIC.


On choisit donc le modèle contenant la constante et les variables _pop_, _prop_, gdp_for_year_, qui minimisent le critère BIC.



### Estimation des paramètres

```{r,echo=TRUE}
mod1 <- lm(deaths~pop+prop+gdp_for_year, data=suicides)
summary(mod1)
```

D'après les résultats de ce test de Fisher global, puisque les quatres variables qu'on a séléctionné ont des p-valeurs très petites (inférieures à 2e-16), on rejette l'hypothèse selon laquelle elles ne seraient pas significatives aux niveaux 1%, 5% et 10%. Nous les incluons donc dans notre modèle. Nous obtenons alors les estimations suivantes des paramètres:

- -1.910e+03 pour la constante
- 8.035e-05 pour la variable _pop_
- 1.874e+07 pour la variable _prop_
- 1.102e-09 pour la variable _gdp_for_year_


### Validation du modèle

Comme dans la partie précédente, nous cherchons à valider les hypothèses de notre modèle.

#### Valeurs atypiques

```{r,echo=FALSE}
rstud <- rstudent(mod1)
plot(1:n,rstud, main='Valeurs abérrantes', xlab = "Index", ylab = "Résidus studentisés")
abline(2,0,col='yellow')
abline(-2,0,col='yellow')
IDvab <- (1:n)[abs(rstud)>2]
points(IDvab, rstud[IDvab], col = 'red', pch = 16) 
text(IDvab, rstud[IDvab], IDvab, pos = 4, col = 'red')
length(IDvab)

```


```{r,echo=FALSE}
levier <- hatvalues(mod1)
plot(1:n,levier,main='Points leviers', xlab = "Index", ylab = "Hat values")
p1 <- mod1$rank
se1 <- 2*p/n
se2 <- 3*p/n
abline(se1,0,col='cyan')
abline(se2,0,col='green')
IDl <- (1:n)[levier>seuil2]
text(IDl, levier[IDl], IDl, pos = 4, col = 'red')
length(IDl)
legend(x=700,y=0.06, col = c("cyan","green"), lty = 1, legend = c("2p/n","3p/n") )
```

```{r,echo=FALSE}
cook <- cooks.distance(mod1)
s1 <- qf(0.5,p,n-p)
plot(1:n,cook,xlab='Index', main='Distance de Cook')
abline(s1,0,col='blue')
s2 <- qf(0.1,p,n-p)
abline(s2,0,col='green')
IDc <- (1:n)[cook>s2]
text(IDc, cook[IDc], IDc, pos = 4, col = 'red')
length(IDc)
legend(x=700,y=0.06, col = "green", lty = 1, legend = "qf(0.1)" )
```


Comme pour la régression simple, on a 48 valeurs abérrantes.
On remarque également un très grand nombre de points leviers (96); on a donc de nombreuses observations influentes dans notre jeu de données. 12 valeurs ont également une distance de Cook élevée. Cependant le deuxième seuil n'est pas dépassée.
On essaie tout de même de tester le jeu de données sans ces observations. 


#### Jeu de données sans les valeurs abérrantes

En supprimant les observations abérrantes on n'a pas de changement sensible dans notre modèle. Supprimer des valeurs de notre jeu de données ne semble donc pas utile.

```{r,echo=FALSE}
data_ab <- suicides[-IDc,]
mod2 <- lm(deaths~.-country,data = data_ab)
summary(mod2)
```



#### Structure des résidus

```{r,echo=FALSE}

plot(1:n,rstandard(mod1),col='black',xlab='Index', main='Résidus standardisés et résidus studentisés', ylab = "Residuals")
points(1:n,rstud,col='orange')
legend(650 , 5,c('standardisé','studentisé'),col=c('black','orange'),pch=c(1,1))
```

A partir de ce graphique, on renouvelle notre hypothèse selon laquelle notre jeu de données contiendrait différentes sous-populations. 
De plus, nous pouvons aussi aperçevoir que les résidus studentisés et standardisés sont très proche voire égaux pour de nombreuses valeurs. 

L'existence d'une structure pourrait également révéler un problème au niveau de l'homoscédasticité.

#### Normalité des résidus

```{r,echo=FALSE}
quant <- qt((1:n)/n,n-p1-1)
plot(quant,sort(rstud),col='pink',main='QQ-plot des résidus',xlab='Student T(n-p-1)',ylab='Quantiles empiriques des résidus')
abline(0,1)
```

```{r,echo=FALSE}
shapiro.test(residuals(mod1))
ks.test(x = (residuals(mod1)-mean(residuals(mod1))/sd(residuals(mod1))), y='pnorm')
```


Encore une fois, le QQ-plot et les test nous confirment que l'hypothèse de normalité des résidus n'est pas réspectée. Notre modèle n'est donc pas un modèle de régression gaussien.


### Conclusion: Régression multiple

En conclusion, le test de Fisher nous indique que les varaibles _prop_, _pop_ et _gdp_for_year sont significatives dans un modèle linéaire de variable réponse _deaths_.
Cependant, plusieurs hypothèses conçernant le bruit restent à enquêter pour pouvoir confirmer le modèle: la présence de sous-populations et les hypothèses d'indépendance et d'homoscédasticité.

## ANOVA

Dans cette partie, nous allons analyser les effets de deux variables qualitatives (l'âge et le sexe) et essaieront de découvrir si ces variables influent ou non sur la proportion de suicides d'une population.
Commençons donc l'analyse sur l'âge:

### Âge

#### Analyse des données et Résultats


Pour nos analyses, nous allons d'abord créer un nouveau __dataframe__ afin de faciliter l'analyse.
Nous obtenons alors un nouveau tableau de la forme suivante:

```{r,echo=FALSE}
data = read.csv(file = "age_sex_modified.csv", header = TRUE, sep = ",")
real_same_age <- data.frame(age = rep(0,nrow(data)), deaths = rep(0,nrow(data)), population = rep(0,nrow(data)))

for (i in (1:nrow(data))){
    real_same_age[i,1] = data$age[i]
    real_same_age[i,2] = data$suicides_no[i]
    real_same_age[i,3] = data$population[i]
}

real_same_age$percentage <- (real_same_age$deaths / real_same_age$population)*100

```
```{r,echo=FALSE}
head(real_same_age)
```
Pour avoir un premier aperçu, nous nous proposons d'étudier la distribution de la proportion de suicide d'une instance de population en fonction de l'âge.
Nous rappelons le codage utilisé pour cette variable:

- 1: 5-14 ans
- 2: 15-24 ans
- 3: 25-34 ans
- 4: 35-54 ans
- 5: 55-74 ans
- 6: 75+ ans

```{r,echo=FALSE}
vect_1 <- real_same_age$age == 1
#vect_1

all_1 <- real_same_age[vect_1,]

vect_2 <- real_same_age$age == 2
#vect_1

all_2 <- real_same_age[vect_2,]

vect_3 <- real_same_age$age == 3
#vect_1

all_3 <- real_same_age[vect_3,]

vect_4 <- real_same_age$age == 4
#vect_1

all_4 <- real_same_age[vect_4,]

vect_5 <- real_same_age$age == 5
#vect_1

all_5 <- real_same_age[vect_5,]

vect_6 <- real_same_age$age == 6
#vect_1

all_6 <- real_same_age[vect_6,]
#mean(all_1$percentage)

boxplot(percentage ~ age , data=real_same_age , main = "Proportion de suicides en fonction de chaque tranche d'âge",xlab = "Tranche d'âge",ylab="Proportion de suicides")
abline(mean(all_1$percentage),0,col="red",lty=4)
abline(mean(all_2$percentage),0,col="blue",lty=4)
abline(mean(all_3$percentage),0,col="cyan",lty=4)
abline(mean(all_4$percentage),0,col="green",lty=4)
abline(mean(all_5$percentage),0,col="violet",lty=4)
abline(mean(all_6$percentage),0,col="black",lty=4)
legend("topleft",legend = c("Mean 5-14 years","Mean 15-24 years","Mean 25-34 years","Mean 35-54 years ","Mean 55-74 years","Mean 75+ years"), col = c("red","blue","cyan","green","violet","black"),lty = 4)
```

En regardant le graphique, on semble observer une corrélation entre l'âge et la proportion de gens qui se suicident.
En effet, chaque indicateur (moyenne, médiane, 3ème quartile...) semble croître dès que l'on passe à une tranche d'âge élevée.
On veut donc tester l'effet de l'âge sur le pourcentage de personnes qui se suicident:
```{r, echo = FALSE}
n <- nrow(real_same_age)
#n
#class(real_same_age$age)
tmp <- as.factor(real_same_age$age)
#tmp
real_same_age$age <- tmp
modu <- lm(percentage ~ age, data = real_same_age)
summary(modu)
# Il est impératif de les tranformer en type factor pour que l'ANOVA se fasse correctement
```
Le test de nullité est significatif pour toutes les classes sauf pour la constante.

De plus, nous obtenons le tableau de l'analyse de la variance suivant:

```{r,echo=FALSE}
anova(modu)
```
Cela nous permet d'affirmer qu'il y a effectivement un effet de l'âge sur la proportion de suicides d'une population.
Il semblerait que la proportion augmente dès lors que l'âge augmente.

#### Analyse des résidus 

Nous pouvons aussi analyser les résidus studentisés pour aperçevoir une éventuelle tendance:
```{r, echo = FALSE}
res_stud <- rstudent(modu)
res_age <- data.frame(index=1:n,residu= res_stud)
res_age <- data.frame(res_age,age=real_same_age$age)
#head(res_age)
par(mfrow = (c(3,2)))

plot(res_age[res_age$age == '1', ]$index, res_age[res_age$age == '1', ]$residu,main="5-14 years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_age[res_age$age == '2', ]$index, res_age[res_age$age == '2', ]$residu,main="15-24 years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_age[res_age$age == '3', ]$index, res_age[res_age$age == '3', ]$residu,main="25-44 years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_age[res_age$age == '4', ]$index, res_age[res_age$age == '4', ]$residu,main="35-54 years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_age[res_age$age == '5', ]$index, res_age[res_age$age == '5', ]$residu,main="55-74 years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_age[res_age$age == '6', ]$index, res_age[res_age$age == '6', ]$residu,main="75+ years",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

```
On observe que le nombre de valeurs dépassant le seuil semble croître au fur et à mesure que l'âge augmente.

Étudions maintenant la distribution des résidus en fonction de chaque tranche d'âge:

```{r, echo = FALSE}
boxplot(residu ~ age, data = res_age,main = "Résidus en fonction de chaque tranche d'âge")
```
On observe une distribution des résidus qui devient de plus en plus large autour de 0 au fur et à mesure que l'âge augmente.
Ceci peut être expliqué par le fait le modèle soit plus adapté aux personnes les plus jeunes, ou aussi par le fait que les pourcentages de suicides pour les populations plus âgées prennent des valeurs plus variées.

```{r, echo=FALSE}
plot(modu,3)
```
De plus, le graphe ci-dessus nous montre qu’il existe un défaut d’homogénéité des résidus. En effet, on peut voir que la variabilité des résidus a tendance à augmenter lorsque l'âge augmente (fitted values).

### Sexe

De la même manière que l'âge, nous allons créer un nouveau jeu de données issu du jeu initial afin de rendre possible nos manoeuvres suivantes. Nous obtenons le tableau suivant qui est de la forme suivante:

```{r, echo=FALSE}
same_sex <- data.frame(sex = rep(0,nrow(data)), deaths = rep(0,nrow(data)), population = rep(0,nrow(data)) )

for (i in (1:nrow(data))){
    same_sex[i,1] = data$sex[i]
    same_sex[i,2] = data$suicides_no[i]
    same_sex[i,3] = data$population[i]
}
same_sex$percentage <- (same_sex$deaths / same_sex$population)*100

vect_male <- same_sex$sex == 1
all_males <- same_sex[vect_male,]

vect_female <- same_sex$sex == 0
all_females <- same_sex[vect_female,]

same_sex[15:20,]


```

#### Analyse des données et Résulats

Nous pouvons regarder la distribution de la proportion de suicides en fonction du sexe:
```{r, echo = FALSE}
boxplot(percentage ~ sex , data = same_sex, main ="Proportion de suicides en fonction du sexe", xlab = "Sexe", ylab = "Pourcentage de suicides" )
abline(mean(all_females$percentage),0 ,col ="red", lty = 4)

abline(mean(all_males$percentage),0 ,col ="blue", lty = 4)
legend("topright" ,legend = c("Moyenne proportion femelle","Moyenne proportion male"), col = c("red","blue"),lty = 4)


```
Encore une fois, on remarque que le sexe semble bel et bien avoir un effet sur la proportion de suicides.
On peut vérifier ça :
```{r, echo = FALSE}
tmp <- as.factor(same_sex$sex)
#tmp
same_sex$sex <- tmp
modu_sex <- lm(percentage ~ sex, data = same_sex)
summary(modu_sex)
anova(modu_sex)
```
La classe de référence est ici le sexe féminin. Le test de nullité des coefficients est cette fois-ci significatif pour la classe du sexe masculin ainsi que la constante.

De plus, le tableau de l'analyse de la variance nous permet d'affirmer que le sexe a un effet sur la proportion de suicides, la p-valeur étant nettement inférieur à $0.001$.
Les hommes seraient donc plus enclins à se suicider à en croire le graphique précédent\...

#### Analyse des résidus
Pour analyser les résidus, nous mettons en place le tableau suivant:
```{r, echo=FALSE}
res_stud_sex <- rstudent(modu_sex)
res_sex <- data.frame(index=1:n,residu= res_stud_sex)
res_sex <- data.frame(res_sex,sex=same_sex$sex)
head(res_sex)
```
Nous pouvons d'abord regarder les résidus en fonction du sexe:
```{r, echo = FALSE}
par(mfrow = (c(1,2)))

plot(res_sex[res_sex$sex == '0', ]$index, res_sex[res_sex$sex == '0', ]$residu,main="Female",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")

plot(res_sex[res_sex$sex == '1', ]$index, res_sex[res_sex$sex == '1', ]$residu,main="Male",ylab="Résidus studentisés",xlab="Indice")
abline(2,0,col="blue")
```
On peut alors s'aperçevoir que il y a beaucoup plus de valeurs abérrantes potentielles dans le groupe des hommes, et cela se répercute sur la distribution de ces résidus:

```{r, echo=FALSE}
boxplot(residu ~ sex, data = res_sex, main = "Résidus en fonction du sexe ", xlab = "Sexe", ylab= "Résidu")
```
En effet, on remarque que la distribution des résidus pour le sexe masculin est beaucoup plus étendue, pouvant être expliqué par le nombre important de grandes valeurs dans le groupe concerné.

### Âge et Sexe 

Nous voulons désormais réaliser une analyse de la variance à deux facteurs, et nous utiliserons les facteurs __age__ et __sex__.
Pour cela, nous mettons à jour le jeu de données pour avoir les deux facteurs ensemble:
```{r, echo=FALSE}
all_inside <- same_sex
all_inside$age <- real_same_age$age
head(all_inside)
```

```{r, echo=FALSE}
boxplot(percentage ~age*sex , data = all_inside, main = "Proportion de suicides en fonction de l'âge et du sexe", xlab = "Age/Sex", ylab = "Percentage")
```
Les six premières \textit{Boîtes à moustaches} correspondant aux différentes tranches d'âge pour la gente féminine, il semble plausible que les deux facteurs aient un effet ainsi qu'une interaction.

```{r, echo=FALSE}
reg <- lm(percentage ~ sex*age, data = all_inside)
summary(reg)
anova(reg)
```
Les tableaux précédents nous semblent confirmer que les deux facteurs ont un effet et qu'il y a aussi une interaction entre les deux, car chaque _p-value_ est extrêmement faible (et donc inférieure à $0.001$ notamment).

Afin de mieux comprendre comment intervient chaque facteur, nous pouvons regarder la figure suivante:
```{r,echo=FALSE}
with(all_inside, interaction.plot(age, sex, percentage))
```

On se rend alors facilement à l'évidence que la proportion de suicides augmente si la tranche d'âge est plus grande.
De manière analogue, la population masculine a une plus grande proportion de suicidaires que la population féminine.

### Conclusion : ANOVA

Ainsi, nous avons pu voir qu'il y a un bien un effet des deux variables quantitatives sur la proportion de suicides d'une population donnée.


## Conclusion Projet / Ouverture

En conclusion, ce projet nous a permis de mettre en épreuve plusieurs outils statistiques sur des données réelles et nous a permis de tirer des informations intéressantes dessus.
De plus, le fait que ce jeu de données était assez mal construit fut une expérience enrichissante car il nous a fallu l'adjuster et travailler pour la rendre exploitable. Les jeux de données du quotidien étant rarement construits parfaitement, le projet a été 
un bon entraînement pour le futur.


D'autre part, un chemin n'ayant pas pu être exploré par soucis de temps est la prédiction: nous aurions pu tester l'efficacité du modèle de régression en le testant face à des données inconnues jusque-là.
